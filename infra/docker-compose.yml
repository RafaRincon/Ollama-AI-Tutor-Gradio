services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    command: ["serve"]              
    environment:
      - OLLAMA_HOST=${OLLAMA_HOST:-0.0.0.0:11434}
      - OLLAMA_MODELS=/models
      - OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE:-5m}
      # - OLLAMA_ORIGINS=${OLLAMA_ORIGINS}
    volumes:
      - ollama-models:/models
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 15s
      timeout: 3s
      retries: 20
    restart: unless-stopped

  app:
    build:
      context: ..
      dockerfile: app/Dockerfile
    container_name: gradio-app
    depends_on:
      ollama:
        condition: service_healthy 
    env_file:
      - ../.env
    environment:
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://ollama:11434}
      - GRADIO_SERVER_NAME=0.0.0.0
      - GRADIO_SERVER_PORT=${APP_PORT:-7860}
    ports:
      - "${APP_PORT:-7860}:7860"
    healthcheck:
      test:
        - CMD-SHELL
        - |
          python - << 'PY'
          import urllib.request,sys
          try:
              urllib.request.urlopen('http://localhost:7860', timeout=3)
              sys.exit(0)
          except Exception:
              sys.exit(1)
          PY
      interval: 15s
      timeout: 5s
      retries: 20
    restart: unless-stopped

volumes:
  ollama-models: